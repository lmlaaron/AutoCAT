{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3462b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 11:36:24,148\tWARNING deprecation.py:45 -- DeprecationWarning: `ray.rllib.utils.torch_ops.[...]` has been deprecated. Use `ray.rllib.utils.torch_utils.[...]` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "# using ray 1.9 to run\n",
    "# python 3.9\n",
    "\n",
    "from ray.rllib.agents.ppo.ppo_torch_policy import PPOTorchPolicy\n",
    "from ray.rllib.agents.a3c.a3c_torch_policy import A3CTorchPolicy\n",
    "from ray.rllib.agents.a3c.a2c import A2CTrainer\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "import gym\n",
    "import ray.tune as tune\n",
    "from torch.nn import functional as F\n",
    "from typing import Optional, Dict\n",
    "import torch.nn as nn\n",
    "import ray\n",
    "from collections import deque\n",
    "#from ray.rllib.agents.ppo.ppo_torch_policy import ValueNetworkMixin\n",
    "from ray.rllib.evaluation.episode import MultiAgentEpisode\n",
    "from ray.rllib.evaluation.postprocessing import compute_gae_for_sample_batch, \\\n",
    "    Postprocessing\n",
    "from ray.rllib.models.action_dist import ActionDistribution\n",
    "from ray.rllib.models.modelv2 import ModelV2\n",
    "#from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.policy.policy import Policy\n",
    "from ray.rllib.policy.policy_template import build_policy_class\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "from ray.rllib.utils.annotations import Deprecated\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.utils.torch_ops import apply_grad_clipping, sequence_mask\n",
    "from ray.rllib.utils.typing import TrainerConfigDict, TensorType, \\\n",
    "    PolicyID, LocalOptimizer\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "import copy\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "torch, nn = try_import_torch()\n",
    "from cache_guessing_game_env_impl import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3868549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_init(policy: Policy, obs_space: gym.spaces.Space, \n",
    "              action_space: gym.spaces.Space, config: TrainerConfigDict)->None:\n",
    "        #pass\n",
    "        policy.past_len = 5        \n",
    "        policy.past_models = deque(maxlen =policy.past_len)\n",
    "        policy.timestep = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c77ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model(model: ModelV2) -> ModelV2:\n",
    "    copdied_model= TorchModelV2(\n",
    "        obs_space = model.obs_space,\n",
    "        action_space = model.action_space, \n",
    "        num_outputs = model.num_outputs,\n",
    "        model_config = model.model_config,\n",
    "        name = 'copied')\n",
    "    \n",
    "    return copied_model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e7ee674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_div_loss(policy: Policy, model: ModelV2,\n",
    "                      dist_class: ActionDistribution,\n",
    "                      train_batch: SampleBatch):\n",
    "    logits, _ = model.from_batch(train_batch)\n",
    "    values = model.value_function()\n",
    "    valid_mask = torch.ones_like(values, dtype=torch.bool)\n",
    "    dist = dist_class(logits, model)\n",
    "    log_probs = dist.logp(train_batch[SampleBatch.ACTIONS])#.reshape(-1) \n",
    "    print('log_probs')\n",
    "    #print(log_probs)\n",
    "    divs = []\n",
    "    div_metric = nn.KLDivLoss(size_average=False, reduce=False)\n",
    "    #div_metric = nn.CrossEntropyLoss()\n",
    "    #if len(policy.past_models) > 1:\n",
    "    #    assert(policy.past_models[0].state_dict() == policy.past_models[1].state_dict())\n",
    "    \n",
    "    for idx, past_model in enumerate(policy.past_models):\n",
    "        #assert(False)\n",
    "        past_logits, _ = past_model.from_batch(train_batch)\n",
    "        past_values = past_model.value_function()\n",
    "        past_valid_mask = torch.ones_like(past_values, dtype=torch.bool)\n",
    "        past_dist = dist_class(past_logits, past_model)\n",
    "        past_log_probs = past_dist.logp(train_batch[SampleBatch.ACTIONS])#.reshape(-1) \n",
    "        div = div_metric(log_probs * train_batch[Postprocessing.ADVANTAGES], past_log_probs* train_batch[Postprocessing.ADVANTAGES])\n",
    "        #div = div_metric(log_probs, past_log_probs) * train_batch[Postprocessing.ADVANTAGES]\n",
    "        #div = dist.multi_kl(past_dist) * train_batch[Postprocessing.ADVANTAGES]\n",
    "        #assert(\n",
    "        \n",
    "        if idx == 0 and True:#policy.timestep % 10 == 0:\n",
    "            print('past_model.state_dict()')\n",
    "            #print(past_model.state_dict())\n",
    "            print('model.state_dict()')\n",
    "            #print(model.state_dict())\n",
    "            #div = past_dist.multi_kl(dist)\n",
    "            print('div')\n",
    "            #print(div)\n",
    "    \n",
    "        div = div.mean(0)\n",
    "        divs.append(div)\n",
    "    print('divs')\n",
    "    #print(divs)\n",
    "    div_loss = 0\n",
    "    div_loss_orig = 0\n",
    "\n",
    "    for div in divs:\n",
    "        div_loss += div\n",
    "        div_loss_orig += div\n",
    "    div_loss = div_loss / policy.past_len\n",
    "    print('policy.past_len')\n",
    "    print(policy.past_len)\n",
    "    return div_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586fd46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def custom_loss(policy: Policy, model: ModelV2,\n",
    "                      dist_class: ActionDistribution,\n",
    "                      train_batch: SampleBatch) -> TensorType:\n",
    "    logits, _ = model.from_batch(train_batch)\n",
    "    values = model.value_function()\n",
    "    policy.timestep += 1\n",
    "    #if len(policy.devices) > 1:\n",
    "        # copy weights of main model (tower-0) to all other towers type\n",
    "    if policy.timestep % 100 == 0:\n",
    "        copied_model = pickle.loads(pickle.dumps(model))\n",
    "        copied_model.load_state_dict(model.state_dict())\n",
    "        policy.past_models.append(copied_model)\n",
    "    \n",
    "    if policy.is_recurrent():\n",
    "        B = len(train_batch[SampleBatch.SEQ_LENS])\n",
    "        max_seq_len = logits.shape[0] // B\n",
    "        mask_orig = sequence_mask(train_batch[SampleBatch.SEQ_LENS],\n",
    "                                  max_seq_len)\n",
    "        valid_mask = torch.reshape(mask_orig, [-1])\n",
    "    else:\n",
    "        valid_mask = torch.ones_like(values, dtype=torch.bool)\n",
    "    dist = dist_class(logits, model)\n",
    "    log_probs = dist.logp(train_batch[SampleBatch.ACTIONS]).reshape(-1)\n",
    "    \n",
    "    #print('log_probs')\n",
    "    #print(log_probs)\n",
    "    \n",
    "    pi_err = -torch.sum(\n",
    "        torch.masked_select(log_probs * train_batch[Postprocessing.ADVANTAGES],\n",
    "                            valid_mask))\n",
    "    # Compute a value function loss.\n",
    "    if policy.config[\"use_critic\"]:\n",
    "        value_err = 0.5 * torch.sum(\n",
    "            torch.pow(\n",
    "                torch.masked_select(\n",
    "                    values.reshape(-1) -\n",
    "                    train_batch[Postprocessing.VALUE_TARGETS], valid_mask),\n",
    "                2.0))\n",
    "    # Ignore the value function.\n",
    "    else:\n",
    "        value_err = 0.0\n",
    "    entropy = torch.sum(torch.masked_select(dist.entropy(), valid_mask))\n",
    "    div_loss = compute_div_loss(policy, model, dist_class, train_batch)\n",
    "    total_loss = (pi_err + value_err * policy.config[\"vf_loss_coeff\"] -\n",
    "                  entropy * policy.config[\"entropy_coeff\"] - 1000 * div_loss )\n",
    "    print('pi_err')\n",
    "    #print(pi_err)\n",
    "    print('value_err')\n",
    "    #print(value_err)\n",
    "    print('div_loss')\n",
    "    print(div_loss)\n",
    "    print('pi_err')\n",
    "    print(pi_err)\n",
    "    print('total_loss')\n",
    "    print(total_loss)\n",
    "    \n",
    "    # Store values for stats function in model (tower), such that for\n",
    "    # multi-GPU, we do not override them during the parallel loss phase.\n",
    "    model.tower_stats[\"entropy\"] = entropy\n",
    "    model.tower_stats[\"pi_err\"] = pi_err\n",
    "    model.tower_stats[\"value_err\"] = value_err\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ce86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomPolicy = A3CTorchPolicy.with_updates(\n",
    "    name=\"MyCustomA3CTorchPolicy\",\n",
    "    loss_fn=custom_loss,\n",
    "    #make_model= make_model,\n",
    "    before_init=custom_init)\n",
    "CustomTrainer = A2CTrainer.with_updates(\n",
    "    get_policy_class=lambda _: CustomPolicy)\n",
    "#PPOCustomPolicy = PPOTorchPolicy.with_updates(\n",
    "#    name=\"MyCustomA3CTorchPolicy\",\n",
    "#    loss_fn=custom_loss,\n",
    "#    #make_model= make_model,\n",
    "#    before_init=custom_init)\n",
    "\n",
    "from typing import Dict, List, Type, Union\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "class CustomPPOTorchPolicy(PPOTorchPolicy):\n",
    "    def __init__(self, observation_space, action_space, config):\n",
    "        self.past_len = 5        \n",
    "        self.past_models = deque(maxlen =self.past_len)\n",
    "        self.timestep = 0\n",
    "        super(CustomPPOTorchPolicy, self).__init__(observation_space, action_space, config)\n",
    "\n",
    "    #@override(PPOTorchPolicy)\n",
    "    def loss(self, model: ModelV2, dist_class: Type[ActionDistribution],\n",
    "             train_batch: SampleBatch) -> Union[TensorType, List[TensorType]]:\n",
    "        #return custom_loss(self, model, dist_class, train_batch)\n",
    "    \n",
    "        self.timestep += 1\n",
    "        if self.timestep % 20 == 0:\n",
    "            copied_model = pickle.loads(pickle.dumps(model))\n",
    "            copied_model.load_state_dict(model.state_dict())\n",
    "            self.past_models.append(copied_model)\n",
    "        \n",
    "        total_loss = PPOTorchPolicy.loss(self, model, dist_class, train_batch)\n",
    "        #self.past_len\n",
    "        div_loss = compute_div_loss(self, model, dist_class, train_batch)\n",
    "        print('total_loss')\n",
    "        print(total_loss)\n",
    "        print('div_loss')\n",
    "        print(div_loss)\n",
    "        #assert(False)\n",
    "        ret_loss = total_loss - 0.1 * div_loss\n",
    "        return ret_loss\n",
    "        '''\n",
    "        new_loss = []\n",
    "        if issubclass(type(total_loss),TensorType):\n",
    "            return total_loss - compute_div_loss(self, model, dist_class, train_batch)\n",
    "        else:            \n",
    "            for loss in total_loss:\n",
    "                new_loss.append(loss - compute_div_loss(self, model, dist_class, train_batch))\n",
    "            return new_loss\n",
    "        '''\n",
    "        \n",
    "PPOCustomTrainer = PPOTrainer.with_updates(\n",
    "    get_policy_class=lambda _: CustomPPOTorchPolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f7356c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/node.py\u001b[0m in \u001b[0;36mget_gcs_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcs_client\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                         ray._private.gcs_utils.GcsClient.create_from_redis(\n\u001b[0m\u001b[1;32m    460\u001b[0m                             self.create_redis_client())\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/_private/gcs_utils.py\u001b[0m in \u001b[0;36mcreate_from_redis\u001b[0;34m(redis_cli)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_from_redis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredis_cli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGcsClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcsChannel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredis_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredis_cli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/_private/gcs_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, channel, address, nums_reconnect_retry)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nums_reconnect_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnums_reconnect_retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/_private/gcs_utils.py\u001b[0m in \u001b[0;36m_connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         self._kv_stub = gcs_service_pb2_grpc.InternalKVGcsServiceStub(\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/_private/gcs_utils.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_redis_client\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mgcs_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gcs_address_from_redis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_redis_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/_private/gcs_utils.py\u001b[0m in \u001b[0;36mget_gcs_address_from_redis\u001b[0;34m(redis)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgcs_address\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to look up gcs address through redis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgcs_address\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to look up gcs address through redis",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cc5de8fae759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m'framework'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m }\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPOCustomTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#config={\"env\": 'Freeway-v0', \"num_gpus\":1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial_executor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTrialExecutor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0m_ray_auto_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_remote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36m_ray_auto_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    752\u001b[0m                     \u001b[0;34m\"For cluster usage or custom Ray initialization, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \"call `ray.init(...)` before `tune.run`.\")\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, _enable_object_reconstruction, _redis_max_memory, _plasma_directory, _node_ip_address, _driver_object_store_memory, _memory, _redis_password, _temp_dir, _metrics_export_port, _system_config, _tracing_startup_hook, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;31m# handler. We still spawn a reaper process in case the atexit handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;31m# isn't called.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         _global_node = ray.node.Node(\n\u001b[0m\u001b[1;32m    909\u001b[0m             \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0mshutdown_at_exit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# Start processes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_head_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0;31m# Make sure gcs is up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             self.get_gcs_client().internal_kv_put(\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/node.py\u001b[0m in \u001b[0;36mstart_head_processes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_redis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_gcs_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ray_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_monitor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_monitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/node.py\u001b[0m in \u001b[0;36mstart_gcs_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    789\u001b[0m         ]\n\u001b[1;32m    790\u001b[0m         \u001b[0;31m# Init gcs client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gcs_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     def start_raylet(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/ray/node.py\u001b[0m in \u001b[0;36mget_gcs_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Waiting for gcs up {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             ray.experimental.internal_kv._initialize_internal_kv(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tune.run(CustomTrainer, config={\"env\": 'Frostbite-v0', \"num_gpus\":0})#, 'model': { 'custom_model': 'test_model' }})\n",
    "tune.register_env(\"cache_guessing_game_env_fix\", CacheGuessingGameEnv)#Fix)\n",
    "# Two ways of training\n",
    "# method 2b\n",
    "config = {\n",
    "    'env': 'cache_guessing_game_env_fix', #'cache_simulator_diversity_wrapper',\n",
    "    'env_config': {\n",
    "        'verbose': 0,\n",
    "        \"force_victim_hit\": False,\n",
    "        'flush_inst': False,\n",
    "        \"allow_victim_multi_access\": False,\n",
    "        \"attacker_addr_s\": 0,\n",
    "        \"attacker_addr_e\": 3,\n",
    "        \"victim_addr_s\": 0,\n",
    "        \"victim_addr_e\": 1,\n",
    "        \"reset_limit\": 1,\n",
    "        \"cache_configs\": {\n",
    "                # YAML config file for cache simulaton\n",
    "            \"architecture\": {\n",
    "              \"word_size\": 1, #bytes\n",
    "              \"block_size\": 1, #bytes\n",
    "              \"write_back\": True\n",
    "            },\n",
    "            \"cache_1\": {#required\n",
    "              \"blocks\": 2, \n",
    "              \"associativity\": 2,  \n",
    "              \"hit_time\": 1 #cycles\n",
    "            },\n",
    "            \"mem\": {#required\n",
    "              \"hit_time\": 1000 #cycles\n",
    "            }\n",
    "        }\n",
    "    }, \n",
    "    #'gamma': 0.9, \n",
    "    'num_gpus': 1, \n",
    "    'num_workers': 1, \n",
    "    'num_envs_per_worker': 1, \n",
    "    #'entropy_coeff': 0.001, \n",
    "    #'num_sgd_iter': 5, \n",
    "    #'vf_loss_coeff': 1e-05, \n",
    "    'model': {\n",
    "        #'custom_model': 'test_model',#'rnn', \n",
    "        #'max_seq_len': 20, \n",
    "        #'custom_model_config': {\n",
    "        #    'cell_size': 32\n",
    "        #   }\n",
    "    }, \n",
    "    'framework': 'torch',\n",
    "}\n",
    "tune.run(PPOCustomTrainer, config=config)#config={\"env\": 'Freeway-v0', \"num_gpus\":1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c830a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c6261c556ed41f6b350217e2390063022b07e524465b6cb254b84519a5fbad7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
